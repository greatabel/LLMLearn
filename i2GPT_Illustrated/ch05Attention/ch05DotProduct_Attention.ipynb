{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577c9f95-687d-4b11-bdbe-a82ee50febf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 导入 torch\n",
    "import torch.nn.functional as F # 导入 nn.functional\n",
    "# 1. 创建两个张量 x1 和 x2\n",
    "x1 = torch.randn(2, 3, 4) # 形状 (batch_size, seq_len1, feature_dim)\n",
    "x2 = torch.randn(2, 5, 4) # 形状 (batch_size, seq_len2, feature_dim)\n",
    "# 2. 计算原始权重\n",
    "raw_weights = torch.bmm(x1, x2.transpose(1, 2)) # 形状 (batch_size, seq_len1, seq_len2)\n",
    "# 3. 用 softmax 函数对原始权重进行归一化\n",
    "attn_weights = F.softmax(raw_weights, dim=2) # 形状 (batch_size, seq_len1, seq_len2)\n",
    "# 4. 将注意力权重与 x2 相乘，计算加权和\n",
    "attn_output = torch.bmm(attn_weights, x2)  # 形状 (batch_size, seq_len1, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5200247-64a2-4ec2-b8bf-4a0651078c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([[[-1.0947,  0.7559, -0.1305, -0.3207],\n",
      "         [-1.5129,  1.1065, -1.1179, -1.7775],\n",
      "         [ 2.2347,  0.3680,  1.2971,  0.3454]],\n",
      "\n",
      "        [[ 1.2760, -0.8365,  2.2257,  0.9133],\n",
      "         [-1.5223, -0.2582, -1.6784, -1.8040],\n",
      "         [-0.2826, -2.3960, -0.0933, -1.0392]]])\n",
      "x2: tensor([[[-0.8767, -0.5866, -1.3379,  0.4334],\n",
      "         [ 0.4346, -0.1804, -0.2376,  0.3296],\n",
      "         [-0.3172,  0.1906,  1.0777, -0.0929],\n",
      "         [-1.6730,  1.0887,  0.9145, -1.3993],\n",
      "         [-1.2933, -1.4245, -0.2051, -1.5456]],\n",
      "\n",
      "        [[-0.1252,  1.2305, -0.3544, -1.5064],\n",
      "         [ 0.3352, -0.0953, -0.1558, -0.8411],\n",
      "         [-1.5253,  0.4628, -1.7653, -1.2735],\n",
      "         [ 0.9310, -0.0189,  0.8817, -1.8977],\n",
      "         [ 0.3707,  0.7684, -0.5354,  0.0670]]])\n"
     ]
    }
   ],
   "source": [
    "# 创建两个张量 x1 和 x2\n",
    "x1 = torch.randn(2, 3, 4) # 形状 (batch_size, seq_len1, feature_dim)\n",
    "x2 = torch.randn(2, 5, 4) # 形状 (batch_size, seq_len2, feature_dim)\n",
    "print(\"x1:\", x1)\n",
    "print(\"x2:\", x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd08a33-ff8e-43d4-905d-a5dd05e29966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 原始权重： tensor([[[ 0.5518, -0.6868,  0.3805,  2.9838,  0.8615],\n",
      "         [ 1.4024, -1.1773, -0.3488,  5.2006,  3.3569],\n",
      "         [-3.7606,  0.7105,  0.7270, -2.6351, -4.2141]],\n",
      "\n",
      "        [[-3.3537, -0.6075, -7.4257,  1.4329, -1.3003],\n",
      "         [ 3.1852,  1.2932,  7.4629,  0.5313,  0.0151],\n",
      "         [-1.3145,  1.0221,  0.8102,  1.6721, -1.9656]]])\n"
     ]
    }
   ],
   "source": [
    "# 计算点积，得到原始权重，形状为 (batch_size, seq_len1, seq_len2)\n",
    "raw_weights = torch.bmm(x1, x2.transpose(1, 2))\n",
    "print(\" 原始权重：\", raw_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48efd205-a242-4dfd-be43-87d12a142949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 归一化后的注意力权重： tensor([[[6.7219e-02, 1.9480e-02, 5.6634e-02, 7.6505e-01, 9.1617e-02],\n",
      "         [1.8894e-02, 1.4321e-03, 3.2792e-03, 8.4300e-01, 1.3340e-01],\n",
      "         [5.5223e-03, 4.8294e-01, 4.9101e-01, 1.7019e-02, 3.5091e-03]],\n",
      "\n",
      "        [[6.9307e-03, 1.0799e-01, 1.1812e-04, 8.3094e-01, 5.4020e-02],\n",
      "         [1.3636e-02, 2.0559e-03, 9.8278e-01, 9.5964e-04, 5.7266e-04],\n",
      "         [2.4964e-02, 2.5829e-01, 2.0896e-01, 4.9477e-01, 1.3018e-02]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F # 导入 torch.nn.functional\n",
    "# 应用 softmax 函数，使权重的值在 0 和 1 之间，且每一行的和为 1\n",
    "attn_weights = F.softmax(raw_weights, dim=-1) # 归一化\n",
    "print(\" 归一化后的注意力权重：\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885eafe0-0b73-4d92-8ee1-4bd7cb3f2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 注意力输出 : tensor([[[-1.4668,  0.6703,  0.6473, -1.1818],\n",
      "         [-1.5998,  0.7170,  0.7215, -1.3774],\n",
      "         [ 0.0163,  0.0168,  0.4219,  0.0867]],\n",
      "\n",
      "        [[ 0.8287,  0.0241,  0.6842, -1.6747],\n",
      "         [-1.4989,  0.4719, -1.7395, -1.2757],\n",
      "         [ 0.2302,  0.1035,  0.0113, -1.4590]]])\n"
     ]
    }
   ],
   "source": [
    "# 与 x2 相乘，得到注意力分布的加权和，形状为 (batch_size, seq_len1, feature_dim)\n",
    "attn_output = torch.bmm(attn_weights, x2)\n",
    "print(\" 注意力输出 :\", attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05df740-c3ad-4564-ae29-f17ed1a1c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09dfa5-5afd-44bc-b761-58f80e5689d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
