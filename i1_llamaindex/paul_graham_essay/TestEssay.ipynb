{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541e9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"INSERT OPENAI KEY\"\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31d6d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/run-llama/llama_index/blob/main/examples/paul_graham_essay/TestEssay.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c51b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index import TreeIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5010abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43829dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 1 chunks\n",
      "> Building index from nodes: 1 chunks\n"
     ]
    }
   ],
   "source": [
    "new_index = TreeIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e83e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [1]/[1]\n",
      ">[Level 1] Selected node: [1]/[1]\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = new_index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aab86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author wrote short stories and also worked on programming, specifically on an IBM 1401 computer in 9th grade.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e7ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [5]/[5]\n",
      ">[Level 1] Selected node: [5]/[5]\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = query_engine.query(\"What did the author do after his time at Y Combinator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6579235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>After the author's time at Y Combinator, they decided to pursue painting. They wanted to see how good they could get if they focused on it. They spent most of the rest of 2014 painting, but eventually ran out of steam and stopped working on it. They then started writing essays again and also began working on Lisp.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6603e",
   "metadata": {},
   "source": [
    "# Build Tree Index with a custom Summary Prompt, directly retrieve answer from root node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a863b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435828be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 1 chunks\n",
      "> Building index from nodes: 1 chunks\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "query_str = \"What did the author do growing up?\"\n",
    "SUMMARY_PROMPT_TMPL = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    f\"answer the question: {query_str}\\n\"\n",
    ")\n",
    "SUMMARY_PROMPT = PromptTemplate(SUMMARY_PROMPT_TMPL)\n",
    "index_with_query = TreeIndex.from_documents(documents, summary_template=SUMMARY_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a4473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.tree_root_retriever:> Starting query: What did the author do growing up?\n",
      "> Starting query: What did the author do growing up?\n"
     ]
    }
   ],
   "source": [
    "# directly retrieve response from root nodes instead of traversing tree\n",
    "query_engine = index_with_query.as_query_engine(retriever_mode=\"root\")\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36c4caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author engaged in activities such as writing short stories and programming, including working on an IBM 1401 computer in 9th grade and teaching themselves Lisp. They also worked on reverse-engineering a program called SHRDLU for their undergraduate thesis.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9dd2a9",
   "metadata": {},
   "source": [
    "# Using GPT Keyword Table Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45121e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import KeywordTableIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb05ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build keyword index\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = KeywordTableIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ddd6a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.keyword_table.retrievers:> Starting query: What did the author do after his time at Y Combinator?\n",
      "> Starting query: What did the author do after his time at Y Combinator?\n",
      "INFO:llama_index.indices.keyword_table.retrievers:query keywords: ['time', 'y combinator', 'author', 'combinator']\n",
      "query keywords: ['time', 'y combinator', 'author', 'combinator']\n",
      "INFO:llama_index.indices.keyword_table.retrievers:> Extracted keywords: ['time', 'y combinator', 'combinator']\n",
      "> Extracted keywords: ['time', 'y combinator', 'combinator']\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do after his time at Y Combinator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb45779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author's next step after his time at Y Combinator was to pursue his own investment firm. He personally financed the firm and brought on board his partner, Jessica, to join the team.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db136606",
   "metadata": {},
   "source": [
    "# Using GPT List Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99073013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SummaryIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build summary index\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = SummaryIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do after his time at Y Combinator?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efe10f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author's next step after his time at Y Combinator was to pursue his own investment firm. He personally financed the firm and brought on board his partner, Jessica, to join the team.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ce639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e593d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
